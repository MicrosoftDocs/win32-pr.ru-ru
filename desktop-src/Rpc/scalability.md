---
title: Масштабируемость
description: Масштабируемость
ms.assetid: 39327621-b536-4494-9319-9e9d4f534123
keywords:
- Масштабируемость
- Удаленный вызов процедур RPC, рекомендации, масштабируемость
ms.topic: article
ms.date: 05/31/2018
ms.openlocfilehash: 0728e35d9c9b27494014363c448be9965e39eea7
ms.sourcegitcommit: 2d531328b6ed82d4ad971a45a5131b430c5866f7
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 09/16/2019
ms.locfileid: "103888972"
---
# <a name="scalability"></a>Масштабируемость

Термин «масштабируемость» зачастую используется нечасто. Для этого раздела предлагается двойное определение:

-   Масштабируемость — это возможность полностью использовать доступную вычислительную мощность в многопроцессорной системе (2, 4, 8, 32 или больше процессоров).
-   Масштабируемость — это возможность обслуживания большого количества клиентов.

Эти два связанных определения обычно называют *масштабированием*. В конце этого раздела приводятся советы по *масштабированию*.

В этом обсуждении основное внимание уделяется исключительно написанию масштабируемых серверов, а не масштабируемых клиентов, поскольку масштабируемые серверы являются более распространенными требованиями. В этом разделе также рассматривается масштабируемость только в контексте серверов RPC и RPC. Рекомендации по масштабируемости, такие как уменьшение количества конфликтов, предотвращение частого попадания в кэш в глобальных областях памяти или предотвращение ложного совместного доступа, не рассматриваются здесь.

## <a name="rpc-threading-model"></a>Потоковая модель RPC

Когда сервер получает вызов RPC, вызывается Серверная подпрограммы (подпрограммы диспетчера) для потока, предоставляемого RPC. RPC использует адаптивный пул потоков, который увеличивается и уменьшается по мере колебаний рабочей нагрузки. Начиная с Windows 2000, ядро пула потоков RPC является портом завершения. Порт завершения и его использование RPC настроены для выполнения действий, отводимых от 0 до небольших конфликтов. Это означает, что пул потоков RPC агрессивно увеличивает число потоков обслуживания, если некоторые из них блокируются. Он работает с предположения, который блокируется редко, и если поток блокируется, это временное условие, которое быстро разрешается. Такой подход обеспечивает эффективность для небольших серверов состязаний. Например, вызов RPC-сервера, работающего на 8-процессорном 550MHz сервере, доступ к которому осуществляется через высокоскоростную системную сеть (SAN), обеспечивает более 30 000 вызовов в секунду от более 200 удаленных клиентов. Он представляет более 108 000 000 вызовов в час.

В результате интенсивный пул потоков фактически получается в том случае, если состязание на сервере велико. Для иллюстрации представьте себе, что сервер высокой нагрузки используется для удаленного доступа к файлам. Предположим, что сервер использует наиболее простой подход: он просто считывает и записывает файл синхронно в потоке, в котором RPC вызывает серверную подпрограммы. Кроме того, предположим, что у нас есть 4-процессорный сервер, обслуживающий множество клиентов.

Сервер будет начинаться с пяти потоков (в действительности это меняется, но для простоты используются пять потоков). После того как RPC выберет первый вызов RPC, он отправляет вызов серверной процедуры, а Серверная подпрограммы выдает операции ввода-вывода. Нередко она пропустила файловый кэш, а затем блокирует ожидание результата. Как только он блокируется, пятый поток освобождается для получения запроса, а шестой поток создается как горячая резервная. Предполагая, что каждая десятая операция ввода-вывода пропустила кэш и будет блокироваться в течение 100 миллисекунд (произвольное значение времени) и при условии, что 4-процессорный сервер обслуживает около 20 000 вызовов в секунду (5 000 вызовов на процессор), упрощенное моделирование порождает, что каждый процессор будет порождать примерно 50 потоков. Это предполагает, что вызов, который будет блокироваться, происходит каждые 2 миллисекунд, и после 100 миллисекунд первый поток освобождается снова, поэтому пул будет стабилизироваться около 200 потоков (50 на каждый процессор).

Фактическое поведение более сложно, так как большое число потоков приведет к появлению дополнительных переключений контекста, которые замедляют работу сервера, а также снижают скорость создания новых потоков, но основная идея очевидна. Число потоков быстро начинает выполняться по мере того, как потоки на сервере начинают блокироваться и ожидают чего-либо (это операция ввода-вывода или доступа к ресурсу).

RPC и порт завершения, на которых поступают входящие запросы, будут пытаться поддерживать количество используемых на сервере потоков RPC, равное числу процессоров на компьютере. Это означает, что на сервере с четырьмя процессорами, когда поток возвращается в RPC, при наличии четырех или более используемых потоков RPC пятый поток не может выбрать новый запрос, а вместо этого будет находиться в состоянии горячей замены в случае, если один из используемых в настоящий момент блоков потоков. Если Пятый поток ожидает достаточно длительного времени в режиме "горячего" резервирования без количества используемых потоков RPC, которые ниже количества процессоров, он будет освобожден, то есть пул потоков будет уменьшаться.

Представьте себе сервер с большим количеством потоков. Как было сказано выше, сервер RPC завершает работу с большим количеством потоков, но только в случае частого блокирования потоков. На сервере, на котором потоки часто блокируются, поток, возвращающий RPC, вскоре выводится из списка "горячего" резервирования, так как все используемые в настоящий момент потоки блокируются и получают запрос на обработку. Когда поток блокируется диспетчером потоков в контексте коммутаторов ядра в другом потоке. Этот контекстный переключатель сам по себе потребляет циклы ЦП. Следующий поток будет выполнять другой код, обращаться к различным структурам данных и будет иметь другой стек. Это означает, что частота попаданий в кэш памяти (кэш L1 и L2) будет значительно ниже, что приведет к более медленному выполнению. Многочисленные одновременно выполняющиеся потоки увеличивают состязание за существующие ресурсы, такие как куча, критические разделы в серверном коде и т. д. Это еще больше повышает состязание, как колонны в формах ресурсов. Если память мала, то недостаток памяти, вызванный большим и увеличивающимся числом потоков, вызовет сбои страниц, что еще больше увеличивает скорость блокировки потоков и вызывает создание еще большего числа потоков. В зависимости от частоты блокировки и объема доступной физической памяти сервер может либо стабилизироваться на более низком уровне производительности с частотой переключения контекста, либо снижаться до того момента, когда к жесткому диску и переключению контекста происходит только многократный доступ без выполнения реальной работы. В этой ситуации не будет отображаться небольшая рабочая нагрузка, разумеется, но большая рабочая нагрузка быстро выводит проблему на поверхность.

Как это можно предотвратить? Если предполагается, что потоки блокируются, объявите вызовы как асинхронные и после того, как запрос введет серверную подсистему, помещает его в пул рабочих потоков, использующих асинхронные возможности системы ввода-вывода и (или) RPC. Если сервер, в свою очередь, выполняет вызовы RPC, сделайте их асинхронными и убедитесь, что очередь не слишком велика. Если серверная часть выполняет файловый ввод-вывод, используйте асинхронный файловый ввод-вывод для постановки в очередь нескольких запросов к системе ввода-вывода и постановки в очередь всего нескольких потоков и получения результатов. Если серверная процедура выполняет операции сетевого ввода-вывода, снова используйте асинхронные возможности системы, чтобы выдать запросы и получать ответы асинхронно и использовать как можно меньше потоков. По завершении ввода-вывода или вызова RPC, выполненного сервером, завершите асинхронный вызов RPC, который доставил запрос. Это позволит серверу работать с минимально возможным количеством потоков, что повышает производительность и число клиентов, которые сервер может обслуживать.

## <a name="scale-out"></a>Горизонтальное увеличение масштаба

RPC может быть настроен для работы с балансировкой сетевой нагрузки (NLB), если NLB настроена так, что все запросы от заданного адреса клиента отправляются на один и тот же сервер. Поскольку каждый клиент RPC открывает пул подключений (Дополнительные сведения см. в разделе [RPC и сеть](rpc-and-the-network.md)), важно, чтобы все соединения из пула данного клиента настроились на одном и том же компьютере сервера. При условии соблюдения этого условия можно настроить кластер балансировки сетевой нагрузки для работы в качестве одного большого сервера RPC с потенциально отличной масштабируемостью.

 

 




